# Phase 3 Testing Guide: Predictive Alpha Portfolio Optimizer

## üéØ Overview

Phase 3 adds **institutional-grade machine learning** to predict stock returns, moving beyond historical sample means to genuine predictive modeling with proper alpha-risk separation.

### Key Innovations

1. **ML-Based Return Forecasts**: Ridge, LASSO, Random Forest, Gradient Boosting
2. **Alpha-Risk Separation**: Short windows for alpha, long windows for risk
3. **Information Coefficient Tracking**: Measures forecast quality
4. **Time-Series Cross-Validation**: Prevents look-ahead bias
5. **Ensemble Modeling**: Combines multiple models for robustness

---

## üöÄ Quick Start Testing

### Backend Setup

```bash
# Navigate to backend
cd backend

# Activate virtual environment
source venv/bin/activate  # Mac/Linux
# OR
venv\Scripts\activate  # Windows

# Install new dependencies (if needed)
pip install -r requirements.txt

# Start Flask server
python app.py
```

**Expected Output:**
```
 * Running on http://0.0.0.0:5000
 * Debug mode: on
```

### Frontend Setup

```bash
# Navigate to frontend
cd frontend

# Install dependencies
npm install

# Start React dev server
npm start
```

**Expected Output:**
```
Compiled successfully!
You can now view the app in the browser.
  Local: http://localhost:3000
```

---

## üß™ Testing Phase 3 (Backend Only - Python)

### Test 1: Predictive Model Standalone

Create `backend/test_phase3_models.py`:

```python
import pandas as pd
import numpy as np
from data_fetcher import fetch_stock_data
from feature_engineering import calculate_features
from predictive_models import PredictiveAlphaModel, EnsembleAlphaModel

def test_predictive_models():
    print("\n" + "="*80)
    print("PHASE 3 MODEL TESTING")
    print("="*80)
    
    # 1. Fetch data
    print("\n[1/6] Fetching stock data...")
    tickers = ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS',
               'HINDUNILVR.NS', 'ITC.NS', 'SBIN.NS', 'BHARTIARTL.NS', 'KOTAKBANK.NS']
    
    stock_data = fetch_stock_data(tickers, '2020-01-01', '2024-11-30')
    print(f"   ‚úì Fetched data for {len(tickers)} stocks")
    
    # 2. Calculate features
    print("\n[2/6] Calculating technical features...")
    features_df = calculate_features(stock_data)
    print(f"   ‚úì Computed {features_df.shape[1]} features")
    print(f"   ‚úì Total samples: {len(features_df)}")
    
    # 3. Prepare price data
    print("\n[3/6] Preparing price data...")
    price_df = stock_data['adj close'].unstack('ticker')
    
    # 4. Test Ridge Model
    print("\n[4/6] Testing Ridge Regression Model...")
    ridge_model = PredictiveAlphaModel(
        model_type='ridge',
        horizon_months=3,
        alpha=1.0
    )
    
    # Generate monthly rebalance dates
    rebalance_dates = pd.date_range(
        start='2021-01-01',
        end='2024-06-30',
        freq='ME'
    )
    
    # Prepare training data
    X, y, dates, tickers_used = ridge_model.prepare_training_data(
        features_df,
        price_df,
        rebalance_dates
    )
    
    print(f"   ‚úì Training samples: {X.shape[0]}")
    print(f"   ‚úì Features: {X.shape[1]}")
    print(f"   ‚úì Unique dates: {len(np.unique(dates))}")
    print(f"   ‚úì Unique tickers: {len(np.unique(tickers_used))}")
    
    # Cross-validate
    cv_results = ridge_model.train_with_cross_validation(X, y, dates, n_splits=3)
    
    print("\n   Cross-Validation Results:")
    print(f"   {'‚îÄ'*60}")
    print(f"   Mean IC:      {cv_results['mean_ic']:.4f} ¬± {cv_results['std_ic']:.4f}")
    print(f"   Mean RMSE:    {cv_results['mean_rmse']:.4f}")
    print(f"   Mean R¬≤:      {cv_results['mean_r2']:.4f}")
    print(f"   {'‚îÄ'*60}")
    
    # Interpret IC
    ic = cv_results['mean_ic']
    if ic > 0.10:
        print("   üéØ EXCELLENT: IC > 0.10 (exceptional predictive skill)")
    elif ic > 0.05:
        print("   ‚úÖ GOOD: IC > 0.05 (statistically significant skill)")
    elif ic > 0.02:
        print("   ‚ö†Ô∏è  MARGINAL: IC > 0.02 (weak but positive signal)")
    else:
        print("   ‚ùå POOR: IC ‚â§ 0.02 (no predictive skill)")
    
    # Train on full data
    print("\n[5/6] Training on full dataset...")
    final_ic = ridge_model.train(X, y)
    print(f"   ‚úì In-sample IC: {final_ic:.4f}")
    
    # Get feature importance
    importance = ridge_model.get_feature_importance(
        feature_names=features_df.columns.tolist(),
        top_n=10
    )
    
    if importance is not None:
        print("\n   Top 10 Most Important Features:")
        print(f"   {'‚îÄ'*60}")
        for idx, row in importance.iterrows():
            print(f"   {idx+1:2d}. {row['feature']:30s} {row['importance']:.4f}")
    
    # Make predictions
    print("\n[6/6] Generating forecasts...")
    latest_date = features_df.index.get_level_values('date').max()
    features_now = features_df.loc[latest_date]
    predictions = ridge_model.predict(features_now.values)
    
    print("\n   Latest Predictions (Expected 3-Month Returns):")
    print(f"   {'‚îÄ'*60}")
    for ticker, pred in zip(features_now.index, predictions):
        print(f"   {ticker:15s} {pred:>8.2%}")
    
    print(f"\n   Summary Statistics:")
    print(f"   {'‚îÄ'*60}")
    print(f"   Mean:    {np.mean(predictions):>8.2%}")
    print(f"   Median:  {np.median(predictions):>8.2%}")
    print(f"   Std:     {np.std(predictions):>8.2%}")
    print(f"   Min:     {np.min(predictions):>8.2%}")
    print(f"   Max:     {np.max(predictions):>8.2%}")
    
    print("\n" + "="*80)
    print("TEST COMPLETE")
    print("="*80)

if __name__ == "__main__":
    test_predictive_models()
```

**Run the test:**
```bash
cd backend
python test_phase3_models.py
```

**Expected Output:**
- IC (Information Coefficient) > 0.05 indicates good predictive skill
- Top features should include RSI, returns, volatility measures
- Predictions should be reasonable (typically -10% to +10% for 3-month horizon)

---

### Test 2: Predictive Walk-Forward Engine

Create `backend/test_phase3_walkforward.py`:

```python
import pandas as pd
from data_fetcher import fetch_stock_data
from walkforward_engine_predictive import PredictiveWalkForwardEngine
import json

def test_predictive_walkforward():
    print("\n" + "="*80)
    print("PHASE 3 WALK-FORWARD TESTING")
    print("="*80)
    
    # Configuration
    tickers = [
        'RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS',
        'HINDUNILVR.NS', 'ITC.NS', 'SBIN.NS', 'BHARTIARTL.NS', 'KOTAKBANK.NS'
    ]
    
    config = {
        'lookback_months': 12,
        'rebalance_freq': 'M',
        'n_clusters': 3,
        'risk_free_rate': 0.06,
        'max_weight': 0.15,
        'min_weight': 0.0,
        'transaction_cost_bps': 15.0,
        'initial_capital': 100000
    }
    
    # Fetch data
    print("\nFetching data...")
    stock_data = fetch_stock_data(tickers, '2020-01-01', '2024-11-30')
    print(f"‚úì Data fetched: {len(stock_data)} rows")
    
    # Test 1: Ridge Model
    print("\n" + "-"*80)
    print("Test 1: Ridge Regression")
    print("-"*80)
    
    engine_ridge = PredictiveWalkForwardEngine(
        stock_data,
        config,
        use_predictive=True,
        model_type='ridge',
        forecast_horizon=3,
        use_ensemble=False,
        alpha_lookback_months=12,
        risk_lookback_months=36
    )
    
    results_ridge = engine_ridge.run()
    
    print("\nüìä Ridge Model Results:")
    print(f"   Total Return:      {results_ridge['metrics']['total_return']:.2%}")
    print(f"   Annualized Return: {results_ridge['metrics']['annualized_return']:.2%}")
    print(f"   Volatility:        {results_ridge['metrics']['volatility']:.2%}")
    print(f"   Sharpe Ratio:      {results_ridge['metrics']['sharpe_ratio']:.2f}")
    print(f"   Max Drawdown:      {results_ridge['metrics']['max_drawdown']:.2%}")
    
    if 'predictive_diagnostics' in results_ridge:
        diag = results_ridge['predictive_diagnostics']
        print(f"\nü§ñ ML Diagnostics:")
        print(f"   Mean IC:           {diag['mean_ic']:.4f}")
        print(f"   IC Stability:      {diag['ic_stability']:.4f}")
        
        if diag['forecast_quality']:
            fq = diag['forecast_quality']
            print(f"   Positive IC Rate:  {fq['positive_ic_ratio']:.1%}")
    
    # Test 2: Random Forest
    print("\n" + "-"*80)
    print("Test 2: Random Forest")
    print("-"*80)
    
    engine_rf = PredictiveWalkForwardEngine(
        stock_data,
        config,
        use_predictive=True,
        model_type='random_forest',
        forecast_horizon=3,
        use_ensemble=False,
        alpha_lookback_months=12,
        risk_lookback_months=36
    )
    
    results_rf = engine_rf.run()
    
    print("\nüìä Random Forest Results:")
    print(f"   Total Return:      {results_rf['metrics']['total_return']:.2%}")
    print(f"   Annualized Return: {results_rf['metrics']['annualized_return']:.2%}")
    print(f"   Volatility:        {results_rf['metrics']['volatility']:.2%}")
    print(f"   Sharpe Ratio:      {results_rf['metrics']['sharpe_ratio']:.2f}")
    print(f"   Max Drawdown:      {results_rf['metrics']['max_drawdown']:.2%}")
    
    # Test 3: Ensemble
    print("\n" + "-"*80)
    print("Test 3: Ensemble Model")
    print("-"*80)
    
    engine_ensemble = PredictiveWalkForwardEngine(
        stock_data,
        config,
        use_predictive=True,
        model_type='ridge',  # Base model for ensemble
        forecast_horizon=3,
        use_ensemble=True,
        alpha_lookback_months=12,
        risk_lookback_months=36
    )
    
    results_ensemble = engine_ensemble.run()
    
    print("\nüìä Ensemble Results:")
    print(f"   Total Return:      {results_ensemble['metrics']['total_return']:.2%}")
    print(f"   Annualized Return: {results_ensemble['metrics']['annualized_return']:.2%}")
    print(f"   Volatility:        {results_ensemble['metrics']['volatility']:.2%}")
    print(f"   Sharpe Ratio:      {results_ensemble['metrics']['sharpe_ratio']:.2f}")
    print(f"   Max Drawdown:      {results_ensemble['metrics']['max_drawdown']:.2%}")
    
    # Comparison
    print("\n" + "="*80)
    print("PERFORMANCE COMPARISON")
    print("="*80)
    print(f"\n{'Model':<20} {'Sharpe':<10} {'Return':<12} {'Volatility':<12}")
    print("-" * 60)
    print(f"{'Ridge':<20} {results_ridge['metrics']['sharpe_ratio']:<10.2f} "
          f"{results_ridge['metrics']['annualized_return']:<12.2%} "
          f"{results_ridge['metrics']['volatility']:<12.2%}")
    print(f"{'Random Forest':<20} {results_rf['metrics']['sharpe_ratio']:<10.2f} "
          f"{results_rf['metrics']['annualized_return']:<12.2%} "
          f"{results_rf['metrics']['volatility']:<12.2%}")
    print(f"{'Ensemble':<20} {results_ensemble['metrics']['sharpe_ratio']:<10.2f} "
          f"{results_ensemble['metrics']['annualized_return']:<12.2%} "
          f"{results_ensemble['metrics']['volatility']:<12.2%}")
    
    print("\n" + "="*80)
    print("TEST COMPLETE")
    print("="*80)

if __name__ == "__main__":
    test_predictive_walkforward()
```

**Run the test:**
```bash
cd backend
python test_phase3_walkforward.py
```

---

## üåê Testing Phase 3 via API (cURL)

### Test API Endpoint

```bash
curl -X POST http://localhost:5000/api/optimize/predictive \
  -H "Content-Type: application/json" \
  -d '{
    "tickers": ["RELIANCE.NS", "TCS.NS", "HDFCBANK.NS", "INFY.NS", "ICICIBANK.NS"],
    "start_date": "2020-01-01",
    "end_date": "2024-11-30",
    "model_type": "ridge",
    "forecast_horizon": 3,
    "use_ensemble": false,
    "alpha_lookback_months": 12,
    "risk_lookback_months": 36,
    "rebalance_freq": "M",
    "max_weight": 0.15,
    "risk_free_rate": 0.06,
    "initial_capital": 100000,
    "benchmark": "NIFTY50",
    "transaction_cost_bps": 15.0
  }'
```

**Expected Response:**
```json
{
  "success": true,
  "mode": "predictive_ml",
  "strategy": {
    "metrics": {
      "total_return": 0.4523,
      "annualized_return": 0.1234,
      "volatility": 0.1856,
      "sharpe_ratio": 0.89,
      "max_drawdown": -0.1523
    },
    "rebalances": [...]
  },
  "ml_diagnostics": {
    "mean_ic": 0.0678,
    "ic_stability": 0.0234,
    "positive_ic_ratio": 0.72
  },
  "benchmark": {...}
}
```

---

## üé® Testing Phase 3 in UI (Once Frontend Updated)

### Step 1: Load Stocks
1. Click "Load NIFTY 50" or manually add tickers
2. Ensure at least 5-10 stocks selected

### Step 2: Set Date Range
- **Start Date**: 2020-01-01 (or earlier)
- **End Date**: 2024-11-30 (current)
- Ensure at least 3 years of data for robust testing

### Step 3: Enable Predictive Mode
1. Toggle "üîÆ Use Predictive Alpha Models"
2. Select model type:
   - **Ridge**: Best for stability (recommended for beginners)
   - **LASSO**: Feature selection, more aggressive
   - **Random Forest**: Captures non-linearities
   - **Gradient Boosting**: Highest potential, but can overfit
3. Set forecast horizon: 3 months (default)
4. Optional: Enable ensemble for robustness

### Step 4: Configure Parameters
- **Alpha Lookback**: 12 months (short window for signals)
- **Risk Lookback**: 36 months (long window for covariance)
- **Rebalance Frequency**: Monthly
- **Max Weight**: 15% (more conservative than Phase 2)
- **Transaction Costs**: 15 bps

### Step 5: Optimize
Click "üöÄ Optimize Portfolio" and wait 30-60 seconds

### Step 6: Review Results

**Strategy Performance:**
- Total Return
- Sharpe Ratio (target: > 0.8)
- Max Drawdown

**ML Diagnostics:**
- Information Coefficient (IC)
  - IC > 0.05: Good predictive skill ‚úÖ
  - IC > 0.10: Excellent ‚≠ê
  - IC < 0.02: Weak ‚ö†Ô∏è
- IC Stability (lower is better)
- Positive IC Rate (% of periods with IC > 0)

**Feature Importance:**
- Top 10 features driving predictions
- Interpret which signals matter most

**Benchmark Comparison:**
- Strategy vs NIFTY 50
- Strategy vs Equal-Weight
- Relative metrics (Alpha, Beta, Information Ratio)

---

## üìã Success Criteria

### Minimum Acceptable Performance
- ‚úÖ IC > 0.03 (statistically significant)
- ‚úÖ Sharpe > 0.6 (better than Phase 2)
- ‚úÖ Beats NIFTY 50 benchmark
- ‚úÖ Max drawdown < 25%
- ‚úÖ No crashes or errors

### Excellent Performance
- ‚≠ê IC > 0.08
- ‚≠ê Sharpe > 1.0
- ‚≠ê Beats benchmark by >200 bps annually
- ‚≠ê Max drawdown < 15%
- ‚≠ê Consistent IC across time

---

## üêõ Troubleshooting

### Issue: "Insufficient training samples"
**Solution**: Increase date range or reduce forecast horizon

### Issue: "IC is negative or very low"
**Possible Causes:**
1. Market regime shift (features trained on bull, testing in bear)
2. Overfitting (try simpler model like Ridge)
3. Look-ahead bias (check data pipeline)
4. Insufficient lookback window

**Solutions:**
- Use Ridge instead of tree models
- Increase alpha lookback to 18-24 months
- Use ensemble for stability
- Check that CV IC is also positive

### Issue: "Optimization fails"
**Solution**: Reduce max_weight constraint, increase min stocks

### Issue: "API timeout"
**Solution**: Reduce number of stocks or use shorter backtest period

---

## üìä Interpreting Results

### Information Coefficient (IC)
Measures correlation between predicted returns and realized returns.

**Interpretation:**
- **IC = 0.10**: Exceptional (top 5% of quant strategies)
- **IC = 0.05-0.10**: Good (institutional quality)
- **IC = 0.02-0.05**: Marginal (statistically significant)
- **IC < 0.02**: No skill (random)
- **IC < 0**: Model worse than random

### Sharpe Ratio Benchmarks
- **< 0.5**: Poor (buy index instead)
- **0.5-0.8**: Acceptable
- **0.8-1.2**: Good
- **> 1.2**: Excellent
- **> 2.0**: Exceptional (often uses leverage)

### Feature Importance
Top features typically include:
1. Multi-horizon returns (momentum)
2. RSI (mean-reversion)
3. Volatility measures (risk regime)
4. MACD (trend)
5. Bollinger Bands (mean-reversion)

If feature importance seems random, model may be overfitting.

---

## üéì Best Practices (Hedge Fund VP Insights)

### 1. Start Conservative
- Use Ridge model first
- Short forecast horizon (1-3 months)
- Monthly rebalancing
- Max 15% per stock

### 2. Validate Out-of-Sample
- Train on 2020-2022
- Test on 2023-2024
- IC should stay positive

### 3. Monitor IC Over Time
- Declining IC ‚Üí Model decay
- Volatile IC ‚Üí Overfitting
- Stable IC ‚Üí Robust strategy

### 4. Use Ensemble for Production
- Reduces model risk
- More stable performance
- Slightly lower peak Sharpe, but better downside

### 5. Benchmark Everything
- Always compare to NIFTY 50
- Track relative metrics (alpha, beta, IR)
- Ensure adding value net of costs

---

## üìÅ Test Data Files

Create `backend/test_data/` with sample outputs for validation.

---

**Questions?** Open an issue on GitHub or check the implementation status document.

**Next Steps:**
1. Run backend tests
2. Verify IC > 0.05
3. Update frontend with predictive controls
4. Deploy and monitor
